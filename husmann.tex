% !TeX root = RJwrapper.tex
\title{Flexible Global Optimization with Simulated-Annealing}
\author{by Kai Husmann, Alexander Lange (and Elmar Spiegel)}

\maketitle

\abstract{
An abstract of less than 150 words.
}

\section{Introduction}
As early computer-based optimization methods developed contemporaneously with the first digital computers \citep{corana_1987}, nowadays numerous optimization methods for various purposes are available \citep{wegener_2005}. One of the main challenges in Operations Research is therefore to match the optimization problem with a reasonable method. The complexity of the problem thereby qualifies the possible methods. Optimization procedures in general can be distinguished into exact methods and heuristics \citep{kirkpatrick_1983}. For simple optimization problems, exact methods are often meaningful tools of choice. If all assumptions on model loss and restrictions are met, these methods will obligatorily find the exact solution without need for further parameters. They are the easiest way of solving optimization problems. The  \dfn{Linear Simplex-Method} \citep{dantzig_1959} as an example which only needs the loss-function and optional restrictions as model input. If, however, any of the model assumptions, e.g. linearity or unimodality, is violated, exact methods are unable to solve problems validly. With developing computer power, heuristics like the Savings-Algorithm \citep{clarke_1964} and metaheuristics like \dfn{Simulated Annealing} (SA) \citep{kirkpatrick_1983} became popular. They enable solving more complex optimization problems. Metaheuristics are a generalization of heuristics with aim to be even more flexible and efficient \citep{blum_2003} such that they can solve complex optimization problems, like nonlinear problems. Depending on the method of choice, more or less assumptions on the loss function can be neglected on the one hand. On the other hand, heuristics and metaheuristics will always solve problems approximately. Precision of the solution depends on the optimization method and further parameters. There is even no guaranty of approximating the actual optimum since the solution also depends, by contrast to exact methods, on parameterization \citep{blum_2003}. Definition of proper parameters is thus a crucial point of those methods. The complexity of parameterization will by trend increase with flexibility of the method while efficiency trends to decrease. Direct search heuristics like the \dfn{Nelder-Mead} (NM) algorithm are comparatively efficient methods which directly converge to the functions optimum and need relatively less settings \citep{geiger_1999}. Random search methods are able to cope with multimodal objective functions. The efficiency and accuracy of such models is strongly sensitive to their parameter specification \citep{corana_1987}. Heuristics are often programmed for multi-purpose usage such that there is a suitable method for many optimization problems. For complex optimization problems, however, multi-purpose optimizers often fail to find solutions. Furthermore multi-purpose optimizers are usually not suitable or not efficient for highly complex problems like problems with restricted parameter space. Whenever general-purpose optimizers are too restrictive or inflexible to solve a problem properly, specific methods are advantageous. Those offer a lot of variable parameters such that they be parameterized very specific to the optimization problem. They represent the most flexible and the most complex optimization methods \citep{blum_2003}.

SA \citep{kirkpatrick_1983} is known to be one of the oldest and most flexible metaheuristic method, though the term metaheuristic was established after initial publication of SA \citep{blum_2003}. It is known to be favorable against many other methods for multimodal loss functions with a very high number of covariates \citep{corana_1987}. The method was applied in many studies among several fields covering e.g. chemistry \citep{agostini_2006}, econometrics \citep{ingber_1993} or forest sciences \citep{baskent_2002}. Since its first implementation by \citet{kirkpatrick_1983}, many authors have modified the algorithm in order to adopt it for specific problems \citep[e.g.][]{desarbo_1989, goffe_1996} or make it more general \citep[e.g.][]{xiang_2013}. It basically combines systematic and a stochastic components, thus enables escaping local optima. It is hence typically used for global optimization of multimodal functions. As it offers a lot of options, SA can be named as hybrid method between a general optimizer (when default values are chosen) and a problem specific optimization algorithm \citep{wegener_2005}. \citet{corana_1987} developed a dynamic adoption method for the variation of the stochastic component during the optimization process. Their modification affects the efficiency as well as the accuracy of the SA algorithm. It has potential to substantially improve the method. \citet{pronzato_1984} suggest to decrease the search-domain of the random component with increasing number of iterations. The stochastic component in general is the most sensitive part of the method since it actually determines the loss variables modification during the iterations.

The R software environment provides platform for simple and effective distribution of statistical models to a huge user community \citep{xiang_2013}. Thus, not surprisingly, several optimization packages of high quality can currently be purchased via \dfn{Comprehensive R Archive Network} \citep{theussl_2016} where even the SA method is recently listed 5 times. We, however, believe, there is need for a specific stochastic optimization package for complex optimization problems. A package coping with very flexible user definable loss functions with multiple options could be an advantageous extension for R. There is demand for specifically definable optimization problems. We therefore present the package \CRANpkg{optimization} which is basically a modified version of SA. We used the properties of SA to program a random search optimization method for specific purposes. We therefore focused on flexibility and implemented many user specifiable parameters. Our method is, in its default configuration, usually not immediately efficient on the one but flexibly adoptable to specific purposes on the other hand. Main advantages of the package are the possibilities to specifically adjust covariate changing rules as well as the the robustness of the loss function. The changing rule allows the user e.g. to define an integer parameter space. The loss function can return any value, even Na or NaN are possible. Several further user specifications help to parameterize the model problem-specific such that the user can influence accuracy and speed very detailed. It is moreover the first R function where the improvements of \citet{corana_1987} and \citet{pronzato_1984} are implemented into an SA based optimization software. This means, the search domain of the stochastic component of SA dynamically shrinks with increasing iterations. We also implemented a generic plot function for post-hoc inspection of the model convergence assessment and the solution quality. In the following, we briefly introduce the algorithm methodologically and explain the most relevant parameters. We show in 4 examples where our model is favorable against existing methods and explain how it can be parameterized. We develop examples illustrating the basic model behavior with ficus on the covariate changing rule. We give hints how to adopt the numerous options to specific problems. Two practical examples where our function is recently used underpin the relevance of our specific-purpose optimization method.

\section{The package optimization}
In this section, theory of our SA interpretation and resulting parameters are explained.

\subsection{Method}
\label{subsec:method}
Simulated Annealing and its derivations are well document in the scientific literature \citep[e.g. in][]{hansen_2012, kirkpatrick_1983, xiang_2013}. We thus mainly concentrate in our methods description on modified and novel implementations. Since the basic idea of Simulated Annealing is derived from the physical process of metal annealing, the nomenclature of SA comes particularly from metallurgy. The classic SA is composed of an inner for and an outer while loop \citep{kirkpatrick_1983}. The number of iterations in both loops are user predefined.

Function of the inner loop(Algorithm \ref{algorithm:pseudocode}) is basically to draw covariate combinations randomly and to compare the returns. The loop is repeated $n_{inner}$ times. After saving the covariate combination of the last inner iteration as $x_j$, the variation function is called to create a new temporary combination $x_{i*}$. In the classical SA approach, the covariates are changed by a uniform distributed random number around $x_j$ \citep{kirkpatrick_1983} which is also the default in our function. The variation function can be changed by the user. It is allowed to depend on a vector with random factors \textit{rf}, $x_j$ and the temperature \textit{t}. By default, the entries in \textit{rf} determine the lower and upper limit of the uniformly distributed random number relative to the current expression of the covariate. A random factor of 0.1 and a covariate expression of 3 for $x_j$ e.g. leads to a random number between 2.7 and 3.3 for $x_{i*}$ if the covariate vector has one entry. The dynamic adaption of \textit{rf} after \citet{corana_1987} and \citet{pronzato_1984} is one of the major novelties of our function. If all entries in $x_{i*}$ after their variation are within the allowed boundaries, the response is calculated. Otherwise the invalid entries of $x_{i*}$ are drawn again until all entries are valid. According to \citet{corana_1987}, the number of invalid trials can be used for dynamical adjustment of the \textit{rf}. The numbers of invalid trials are thus, distinctively for each covariate, counted and stored. If the return of current variables combination $f(x_{i*})$ is better than $f(x_j)$, $x_{i*}$ and $f(x_{i*})$ are stored. Main idea of the SA is to cope with local optima. For this, even if the return of $x_{i*}$ is worse than the return of $x_{j}$ there is a chance of keeping  $x_{i*}$. The former optimal covariate combination is stored before it is overwritten. The likelihood of keeping worse responses decreases with decreasing temperature \textit{t} thus with increasing number of outer loop iterations. The detailed calculation of the Monte-Carlo approach by \citet{metropolis_1953} can i.a. be found in \citet{kirkpatrick_1983}. Storing the development of covariates and response can be help improving the performance of SA \citep{lin_1995, hansen_2012}. We implemented a modification of the threshold accepting strategy \citep{dueck_1990} which enables reducing the total number of calculations. This is archived by simply calculating and storing the improvement as absolute difference of $f(x_{i})$ and $f(x_j)$. If the response oscillates for user defined number of repetitions within a user defined threshold, the inner loop breaks.

\SetAlCapSkip{2ex}
\begin{algorithm}[H]
	initialize \textit{t}, $vf$ with user specifications\\
	calculate $f(x_0)$ with initial parameter vector $x_0$\\
	\While{\textit{t} $>$ $t_{min}$}{
		\For{i in c(1: $n_{inner}$)}{
			$x_j \gets x_{(i-1)}$\\
			call the variation function to generate $x_{i*}$ in dependence of $x_{j}$, \textit{rf} and \textit{t}\\
			check if all entries in $x_{i*}$ are within the boundaries\\
			\eIf{all $x_i$ valid}{calculate $f(x_{i*})$}{
				\While{any($x_{i*}$ invalid)}{
					call the variation function again\\
					count invalid combinations}
			}
			\eIf{$f(x_{i*}) < f(x_j)$}{
				$x_{i} \gets x_{i*}; f(x_{i}) \gets f(x_{i*})$
			}{calculate Metropolis Probability in dependence of \textit{t}\\ \eIf{random 
				number $<$ Metropolis probability}{store $x_j$ and $f(x_j)$\\$x_{i} \gets x_{i*}; f(x_{i}) \gets f(x_{i*})$}{$x_{i} \gets x_j; f(x_{i}) \gets f(x_j)$}}
		\If{threshold accepting criterion fulfilled}{break inner loop}
	}
	
	{
		reduce \textit{t} for the next iteration\\
		$vf$ adaptation for the next iteration\\
	}
}
\textbf{return} optimized parameter vector, function value and some additional informations \\
\caption{Pseudocode of the modified Simulated Annealing method in the \textbf{optimization} package exemplary for a minimization.}
\label{algorithm:pseudocode}
\end{algorithm}

Main functions of the outer loop are calling the inner loop as well as specifying \textit{t} and $vf$ for the next iteration of the outer loop. As \textit{t} obligatory decreases in our derivation of SA, the number of iterations is implicitly user predefined by initial temperature $t_0$ and minimum temperature $t_{min}$. \textit{t} is necessary for the stochastic part within the inner loop \citep{kirkpatrick_1983}. As each covariate can have its own random factor, the vector with random factors \textit{rf} is of the same dimension as $x_i$. Dividing the counted number of invalid trials of a covariate by the total number of trials of the respective covariate gives the ratio of invalid trials distinctively for each covariate. Summing up the valid and invalid trials of all inner loop repetitions gives the mean ratio of invalid trials per outer loop repetition. According to \citep{corana_1987}, this ratio can be used to find a trade-off between accuracy on the one and size of the search-domain on the other side. They argument that if there were only valid covariate combinations, the search domain could be too small for multimodal function. They suggest ratios between 0.4 and 0.6. If any observed ratio is < 0.4 or > 0.6, the respective random factors are modified following the suggested nonlinear equation by \citet{corana_1987} such that they are dynamically adjusted for the next iteration. \citet{pronzato_1984}, who developed the Adaptive Random Search method, propose a time decreasing search domain. We combined the two methods by linearly shrinking the favorable range of ratios from 0.4-0.6 to 0.04-0.06. If the default variation function is chosen, the search domain of the covariates reduces with increasing number of outer loop iterations.


\subsection{The function optim\_sa}
As the function is mainly written in C++, it requires \CRANpkg{Rcpp}. \code{optim\_sa} shall be able to solve very specific optimization problems, several parameters can be defined by the user. Quality of solution and speed of convergence will thus substantially depend on accurate parametrization. In the following, we will explain the most important parameters briefly giving hints for useful specification. A complete parameter list can be found in the vignette.
\begin{itemize}
	\item \code{fun}: Obligatory loss function to be optimized. The function must depend on a vector of covariates and return one numeric value. There are no assumptions on covariates and return. The covariates even need not be continuous. Missing (\code{NA}) or undefined (\code{NaN}) returns are allowed as well. Any restriction on the parameter space, e.g. specific invalid covariate values within the boundaries, can be integrated in the loss function directly by simply returning NA. We will be more specific on this in the practical examples.
	\item \code{start}: Obligatory numeric vector with initial covariate combination. It must be ensured that at least the initial covariate combination leads to a defined numeric response. The loss function at the initial variables combination must therefore return a defined numeric value. This might be relevant when the starting values are determined stochastically.
	\item \code{trace}: If \code{TRUE}, the last inner loop iteration of each outer loop iteration is stored as row in the trace matrix. This might help evaluating the solutions quality. However, storing interim results increases calculation time up to 10 \%. Disabling \code{trace} can thus improve efficiency when the convergence of an optimization problem is known to be stable.
	\item \code{lower, upper}: Numeric vector with lower boundaries of the covariates. The boundaries are obligatory since the dynamic \code{rf} adjustment \citep{corana_1987, pronzato_1984} depends on the number of invalid covariate combinations.
	\item \code{control}: A list with optional further parameters.
\end{itemize}
All parameters in the list with \code{control} arguments have a default value. They are pre-parameterized for loss functions of medium complexity. \code{control} arguments are:
\begin{itemize}
	\item \code{vf}:  \code{vf} allows the user to restrict the parameter space. It is one of the most important differences to classic SA. The function determines the variation of covariates during the iterations. It is allowed to depend on \code{rf}, \code{temperature} and a vector of covariates of the current iteration. The variation function is a crucial element of \code{optim\_sa} which enables flexible programming. It is (next to the loss function itself) the second possibility to define restrictions. The parameter space of the optimization program can be defined \code{vf}. Per default, the covariates are changed by a continuous, uniform distributed random number. It must be considered that defining specific \code{rf} can increase the calculation time. The default \code{rf} is a compiled C++ function whereas user specified \code{rf} must be defined as R functions. User specified are e.g. useful for optimization problems with non-continuous parameter space.
	\item \code{rf}: Numeric vector with random factors. The random factors determine the range of the random number in the variation function vf relative to the dimension of the function variables. The rf can be stated separately for each variable. Default is a vector of ones. If \code{dyn\_rf} is enabled, the entries in \code{rf} change dynamically over time.
	\item \code{dyn\_rf}: If \code{TRUE}, \code{rf} change dynamically over time to ensure increasing precision with increasing number of iterations. \code{rf} determines whether the adjustments of \citet{corana_1987, pronzato_1984} are enabled (see method section for theoretical background). \code{dyn\_rf} ensures a relatively wide search domain at the beginning of the optimization process that shrinks over time. Disabling \code{dyn\_rf} can be useful when \code{rf} with high performance are known. The development of \code{rf} is documented in the \code{trace} matrix. Evaluation of former optimizations with dynamic \code{rf} can thus help finding efficient and reasonable fixed \code{rf}. Self-specified \code{vf} may not depend on \code{rf}. In this cases activating \code{dyn\_rf} makes no sense.
	\item \code{t0}: Initial temperature. The temperature directly influences the likelihood of accepting worse responses thus the stochastic part of the optimization. \code{t0} should be adopted to the loss function complexity. Higher temperatures lead to higher ability of coping with local optima on the one but also to more time-consuming function calls on the other hand.
	\item \code{t\_min}: numeric value that determines the temperature where outer loop stops. As there is practically no chance of leaving local optima in iterations with low temperature \code{t\_min} mainly affects accuracy of the solution. Higher \code{t\_min} yields to lower accuracy and less function calls.
	\item \code{nlimit}: Integer value which determines the maximum number of inner loops iterations. If the break criterion \code{stopac} is not fulfilled, \code{nlimit} is the exact number of inner loops repetitions.
	\item \code{r}: Numeric value that determines the reduction of the temperature at the end of each outer loop. Slower temperature reduction leads to increasing number of function calls. It should be parameterized with respect to \code{nlimit}. High \code{nlimit} in combination with low \code{r} lead to many iterations with the same acceptance likelihood of worse responses. Low \code{nlimit} in combination with \code{r} near 1, by contrast, lead to continuously decreasing acceptance likelihood of worse responses.
\end{itemize}

\section{Examples}
We briefly explain where the \code{optim\_sa} function is advantageous.

\subsection{Himmelblau Function with continuous parameter space}
Himmelblau's function \citep{himmelblau_1972} was chosen as initial example since it is a very simple multimodal equation which is widely known in Operations Research. It has 4 equal minimum values ($min(f(x_1,x_2))=0)$) at \{-2.8, 3.1\}, \{3.0, 2.0\}, \{3.6, -1.8\} and \{-3.8, -3.3\} (Equation \ref{eq:eq1}). In order to display the advantages and basic behavior of \CRANpkg{optimization}, it was compared with 2 other SA methods from the packages \pkg{stats} and \CRANpkg{GenSA}. Himmelblau's function is relatively simple. We therefore also included the NM optimization method \citep{nelder_1965} which is default of \code{optim} from the \pkg{stats} package to examine the advantages of random against direct search.

\begin{equation}
\label{eq:eq1}
f(x_1,x_2)=(x_1^2+x_2-11)^2+(x_1+x_2^2-7)^2
\end{equation}

We performed 10,000 optimizations with each function in order investigate quality and speed of the solutions using parameters for relatively simple optimization problems for all examined methods. The optimizations were performed having the following parameters:

\begin{example}
# stats package: optim (NM)
stats::optim(fn = hi, par = c(10, 10), method = "Nelder-Mead")
	
# optimization package: optim_sa
optimization::optim_sa(fun = hi, start = (c(10, 10)), trace = TRUE, 
	lower = c(-40, -40), uppe r= c(40, 40),
		control = list(t0 = 500, nlimit = 50,r = 0.85,
		rf = 3, ac_acc = 0.1, dyn_rf = TRUE))

# stats package optim (SA)
stats::optim(fn = hi, par = c(10, 10), method = "SANN",
	control = list(tmax = 500, reltol = 0.1, temp = 50, trace = TRUE))

# GenSA package: GenSA
GenSA::GenSA(fn = hi, par = c(10, 10), lower = c(-40, -40), upper = c(40, 40), 
	control = list(temperature = 50, nb.stop.improvement = 30, maxit = 500))
\end{example}
%%Dont forget: No line break
Since we have a multimodal optimization problem with multiple equal solutions, evaluation of solutions quality is composed of response accuracy and covariate combination. With fixed starting parameters, the methods should be able to find all possible solutions. We defined the problem to be solved with sufficient accuracy when the response was $\leq$ 0.01. We also looked at the frequency distribution of the covariate combination after minimization. Subsequent to investigation of quality, we also compared the efficiencies by measuring calculation times using \CRANpkg{microbenchmark}.

It could be seen that parameterization of NM was quite easy. It only needed a vector with starting values. The other functions needed much more settings. With view to accuracy each method performed well. All functions returned in mean of 10,000 calls responses with values $\leq$ 0.01. With view to frequency distribution, the functions performed indifferent (Table \ref{tab:tab1}). \code{optim\_sa} and \code{optim (SA)} returned each possible solutions.  The combination \{-3.8, -3.3\} was consistently least frequent. \code{GenSa} and \code{optim (NM)}, however, solely returned \{-3.8, -3.3\}. Further investigation revealed the solutions of \code{GenSa} and \code{optim (NM)} to be sensitive of the starting values. If \code{GenSa} and \code{optim (NM)} were parameterized with randomly drawn starting values, all 4 results would have been possible. Advantage of \code{optim\_sa} and \code{optim (SA)} against \code{GenSa} and \code{optim (NM)} is, in this example, thus its independence from starting values.

% latex table generated in R 3.2.3 by xtable 1.8-2 package - Modified after pasting
% Tue Mar  7 14:26:30 2017
\begin{table}[]
	\centering
	\caption{Relative frequencies of covariate combinations in \% after optimization for the 4 examined methods. Number of repetitions: 10,000. We used the parameters given in the example except for deactivated trace option.}
	\label{tab:tab1}
	\begin{tabular}{cccccc} \cline{3-6}
& \multicolumn{1}{c}{} & \multicolumn{4}{c}{Result (rounded)}                    \\ \cline{3-6} 
		&                      & \{-2.8, 3.1\} & \{3.0, 2.0\} & \{3.6, -1.8\} & \{-3.8, -3.3\} \\ \cline{2-6} 
		\multirow{4}{*}{Method} & optim\_sa          & 22.19     & 33.49    & 28.05     & 16.27      \\
		& optim (SA)            & 25.91     & 30.89    & 24.08     & 19.12      \\
		& GenSA              & 0.00      & 0.00     & 0.00      & 100.00     \\
		& optim (NM)          & 0.00      & 0.00     & 0.00      & 100.00     \\ \cline{2-6} 
	\end{tabular}
\end{table}

As all functions were practically able to minimize equation \ref{eq:eq1}, comparison of calculation times appears to be another important point for quality assessment. As expected, the direct search method \code{optim NM} was by far faster then all random search methods (Figure \ref{fig:fig1}). The within-group ranking of random search methods revealed \code{GenSA} to be fastest. It was in average 3.5 times faster than \code{optim\_sa}. The 2 functions able coping with equally valued optima (\code{optim (SA)} and \code{optim\_sa}) were slower than \code{GenSA} (Table \ref{tab:tab1}, Figure \ref{fig:fig1}).

To conclude, all functions were generally able to solve the problem. The flexible random search-grid of \code{optim (SA)} and \code{optim\_sa} enabled archiving each of the 4 solutions. Practically, in case users are in doubt whether a problem has multiple solutions with equal responses, \code{optim (SA)} and \code{optim\_sa} can simply be repeated without re-parameterization. If well-specified, they will return all possible solutions. They are thus advantageous for complex multimodal problems of that kind on the one hand, but slower on the other hand. Due to the multiple additional options, which all have to be called in the code, \code{optim\_sa} is slowest. This example clearly reveals that higher flexibility and generality leads to significantly higher calculation times. Specific algorithms are advantageous for complexer problems while more general functions are useful for optimization problems with simple responses.

\begin{figure}[htbp]
	\centering
	\resizebox{.6\linewidth}{!}{\input{Fig/fig1_ex1-time.tex}}
	\caption{Calculation times of the 4 examined optimization algorithms. Note that the y-axis is truncated. \code{optim\_sa} sowed 101 and \code{optim (SA)} 70 outliers between 4 and 7 milliseconds.}
	\label{fig:fig1}
\end{figure}

\subsection{Himmelblau Function with discrete parameter space}
A second example illustrating the advantage of flexibly defining the parameter spaces also bases on the function by \citet{himmelblau_1972}. It is an exemplary optimization problem which cannot be solved with \code{optim()} or \code{GenSA}. If a user is interested in integer covariate combinations only, the variation function  \code{vf} option can be used to restrict the parameter space accordingly. The following simple example shows a variation rule for integer programming problems. The simple \code{var\_fun\_int} from the example returns a vector of integer covariates varying in dimension of \code{vf} around the passed covariates \code{para\_0}. The \code{fun\_length} is passed explicitly, although it is implicitly given by the length of \code{para\_0} because it might help simplifying the \code{vf}. Dependence of \code{rf} and \code{temp} can be implemented. If \code{vf} does not need a dynamic part, i. e. if the stochastic part shall be fixed during the entire iterations, \code{temp} and \code{rf} can separately be disabled by passing \code{NA}. If \code{vf} does not depend on \code{rf}, the option \code{dyn\_rf} will not be useful any more.

\begin{example}
# Define vf
var_fun_int <- function (para_0, fun_length, rf, temp = NA) {
	ret_var_fun <- para_0 + sample.int(rf, fun_length, replace = TRUE) *
	((rbinom(fun_length, 1, 0.5) * -2) + 1)
	return (ret_var_fun)
}

# Call optim_sa
int_programming <- optimization::optim_sa(fun = hi, start = c(10, 10), trace = TRUE, 
	lower = c(-40, -40), upper=c(40, 40),
	control = list(t0 = 500, nlimit = 50,r = 0.85, rf = 3, ac_acc = 0.1,
		dyn_rf = TRUE, vf = var_func_int))
\end{example}

Calling the minimization function always leaded to the only integer solution \{3, 2\}. The generic plot function of \code{optimization} (Figure \ref{fig:fig2}) helps interpreting the convergence and thus the solution quality as well as the algorithm behavior. Since the used example is 2-dimensional, a \code{contour\_plot} (Figure \ref{fig:fig2}. right) could be created. It shows the state space of the Himmelblau function in continuously changing colors. The results at the end of each outer loop iteration are shown as points within the parameter space. Reducing the actual parameter space from the example improves presentation. It became obvious that only integer covariate combinations were calculated during optimization (Figure \ref{fig:fig2}, right). Figure \ref{fig:fig2} additionally helps explaining the stochastic part. It becomes clear that though response of iteration 12 (parameter combination \{-2, 3\}) was already quite near 0, following iteration ended with a relatively worse intermediate results. With response > 100, iteration 21 was much worse than iteration 12. The likelihood of keeping worse solutions shrined over time till it became practically 0 after iteration 30 (Figure \ref{fig:fig2}, left). For problems of such kind, 40 iterations therefore should be far enough. This information could help the user parameterizing the function for the next problem.

\code{optim\_sa} is advantageous against all other \code{SA} based algorithms when the parameter space of the optimization problem underlies extended restrictions. The user can define the valid parameter space within the lower and upper limits. To archive this, the user must define a changing rule in form of a R function. Users must thus examine their optimization problem very carefully and translate it into suitable functions. This example exhibits the properties of \code{optim\_sa} as an example for specific optimization. Its parameterization is quite complex and time extensive but enables adopting the optimizer to problem specific needs. Other restrictions such as mixed integer problems may be defined analogously. \code{vf} can thus be used to flexibly restrict the parameter space. Further hints for interpretation can be found in the package documentation.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=1.025\textwidth]{Fig/fig2-ex2-plot.eps}
	\caption{Examination plots created with the generic plot function. The left diagram shows the current optimal response over iteration of the outer loop. The left diagram displays the succession of the covariate values. The star points the covariate combination at optimum.}
	\label{fig:fig2}
\end{figure}

\subsection{A complexer function?}
\textit{Hat jemand eine Idee fÃ¼r eine weiteres Bsp.? Evtl. multimodal mit lokalen, also nicht gleichwertigen, Minima.}
\subsection{SVAR}
\textit{Alex}
\subsection{Forest harvesting schedule optimization}
Forestry is traditionally knowledge-based field with optimization playing only minor role. However popularity of optimization methods is steadily rising. While Linear Programs are nowadays used in some states, e.g. Finland \citep{redsven_2012}, stochastic optimization programs are quite novel in forestry \citep{kangas_2015}. Our function is integral part of the first stochastic optimization software of forest operation in Germany and one of the first softwares worldwide. Optimization of forest harvesting planning represents an interesting and innovative practical example where \code{optim\_sa} is recently used. \CRANpkg{optimization} is part of the ForestPlanner based decision support software for forest enterprises by \citet{hansen_2014}. ForestPlanner is a user front end for TreeGrowthOpenSourceSoftware (TreeGrOSS) which is a complex Java written tree growth and yield simulation software used to forecast the developments of forest management areas (stands). It is a tool able to simulate forest enterprises with hundreds of forest stands simultaneously where the smallest simulation element is the single tree. Each tree in the system is thus simulated individually. Optimization of forest activities is accordingly not trivial since TreeGrOSS is a complex network of rules and functions which are predominantly nonlinear. The entire optimization process is composed of TreeGrOSS, \CRANpkg{optimization} and a data warehouse. This multi-factorial composition implies high demand for flexibility of the optimization function. Loss function, which represents in this example the interface between the 3 elements of the optimization system, must be composed of R, Java (using \CRANpkg{rJava}) and SQL (using \CRANpkg{RPostgreSQL}). Main tasks of the interface are enabling communication between TreeGrOSS and optimization algorithm and rating the TreeGrOSS output in terms of costs and revenue such that the TreeGrOSS output is translated into an optimizable response. Flexibility of loss and variation functions is hence a prerequisite for forest harvesting schedule optimization via TreeGrOSS simulations. Each loss function call causes a TreeGrOSS simulation and a database operation. In order to save time, parts of the loss are therefore programmed parallel. The response is, accordingly, nonlinear and particularly non-continuous. Random search methods are of therefore favorable for the problem. Obligatory sustainability of forest stand treatment is also considered in form of restrictions. Each function call returns, next to the actual response, a sustainability index. This index is used to restrict the optimization by simply defining \code{NA} responses whenever sustainability is violated.

It showed that forest treatment optimization was actually possible using \CRANpkg{optimization}. We developed a loss function able translating the TreeGrOSS in- and output into interpretable variables for \code{optim\_sa}. Sensitivity analysis using an exemplary forest enterprise comprised of 5 forest stands, with known global maximum, reinforced reliability of \code{optim\_sa} for harvesting optimization. A solution sufficiently near the global maximum was found in arguable time on a standard personal computer. To test the practical usability, the optimization system was additionally tested on a real forest enterprise with 100 forest stands. The problem was solved within 12 hours using a cluster computer. Repeating the optimization 3 times leaded to equal responses but different harvesting volumes (thus covariate combinations). This again reveals the complexity of the problem and further reinforces the need for specific stochastic methods.


\section{Discussion and outlook}
It does not guarantee, of course, to find the global minimum, but if the function has many good near- optimal solutions, it should find one. In particular, this method is able to discriminate between gross behavior of the function and finer wrinkles. First, it reaches an area in the function domain where a global minimum should be present, following the gross behavior irrespectively of small local minima found on the way. It then develops finer details, finding a good, near-optimal local minimum, if not the global minimum itself.\\

Every method has advantages and disadvantages: GenSA for example is by far most efficient. It should be used for problems with 1 global optimum. optim\_sa has its niche -> mult. equal opt. = felxible loss; NA returns
-> enrichment of the optimization procedures in R  

Example 1 shows -> Our is slowest but together with optim (SA) best
Ex 2 shows -> Our is the only one that solves the problem
	--> Slow but flexible

\bibliography{husmann}

\address{Author One\\
  Affiliation\\
  Address\\
  Country\\}
\email{author1@work}

\address{Author Two\\
  Affiliation\\
  Address\\
  Country\\}
\email{author2@work}

\address{Author Three\\
  Affiliation\\
  Address\\
  Country\\}
\email{author3@work}

% !TeX root = RJwrapper.tex
\title{Flexible Global Optimization with Simulated-Annealing}
\author{by Kai Husmann, Alexander Lange (and Elmar Spiegel)}

\maketitle

\abstract{
An abstract of less than 150 words.
}

\section{Introduction}

As early computer-based optimization methods developed contemporaneously with the first digital computers \citep{corana_1987}, nowadays numerous optimization methods for various purposes are available \citep{wegener_2005}. One of the main challenges in Operations Research is therefore to match the optimization problem with a reasonable method. According to  \citet{kirkpatrick_1983}, optimization procedures in general can be distinguished into exact methods and heuristics. In case the loss function of the optimization problem shows quite simple responses, exact methods are often meaningful tools of choice. If all assumptions on model loss and restrictions are met, these methods will obligatorily find the exact solution without need for further parameters. The  \textit{Linear Simplex-Method} \citep{dantzig_1959} as an example only needs the loss-function and optional restrictions as model input. If, however, any of the model assumptions, e. g. linearity or unimodality, is violated, exact methods are unable to solve the problems validly. In practice, they thus lack applicability whenever a loss function is too complex. With developing computer power heuristics like the Savings-Algorithm \citep{clarke_1964} and metaheuristics became more and more popular. Both enable solving optimization problems of more flexible loss functions. Metaheuristics are a generalization of heuristics with aim to be even more flexible and efficient \citep{blum_2003}. Depending on the method of choice, more or less assumptions on the loss function can be neglected. On the other hand heuristics and metaheuristics will always solve problems approximately. Precision of the solution depends on loss, optimization method and further parameterizations of the respective method. There is even no guaranty of approximating the actual optimum since the solution also depends, by contrast to exact methods, on parameterization \citep{blum_2003}. Heuristic and metaheuristic methods will thus always need additional parameters next to the loss function. Finding the proper model parameters is thus a crucial point when applying heuristic or metaheuristic algorithms. The complexity of parameterization will by trend increase with flexibility of the method. Direct search methods like the \textit{Nelder-Mead} (NM) algorithm are comparatively efficient methods which directly converge to the functions optimum and need relatively less settings \citep{geiger_1999}. Random search methods are able to cope with multimodal objective functions as they have a random component which allows leaving local optima. The efficiency and accuracy of such models is usually highly sensitive to their parameter specification \citep{corana_1987}.

\textit{Simulated Annealing} (SA) \citep{kirkpatrick_1983} is known to be one of the oldest and one of the most flexible and generalized metaheuristic method \citep{blum_2003}, though the term 'metaheuristic' was established after first publication of SA. It is known to be favorable against most other methods for multimodal loss functions with a very high number of covariates \citep{corana_1987}. The method was applied in many studies among several fields covering e. g. chemistry \citep{agostini_2006}, econometrics \citep{ingber_1993} or forest sciences \citep{baskent_2002}. Since its first implementation by \citet{kirkpatrick_1983}, many authors have modified the algorithm in order to adopt it for specific problems \citep[e. g.][]{desarbo_1989, goffe_1996} or make it more efficient \citep[e. g.][]{xiang_2013}. It is basically a combination of systematic and a stochastic components. The stochastic part of the algorithm allows keeping worse responses in each iteration step during the optimization process. This enables searching for the global optimum even for multimodal loss functions. As it offers a lot of options, SA can be named as hybrid method between a general optimizer (when default values are chosen) and a problem specific optimization program \citep{wegener_2005}. \citet{corana_1987} developed a dynamic adoption method for the variation of the stochastic component during the optimization process. Their modification affects the efficiency as well as the accuracy of the SA algorithm. It has potential to substantially improve the method. \citet{pronzato_1984} suggest to decrease the search-domain of the random component with increasing number of iterations. The stochastic component in general is the most sensitive part of the method since it actually determines the loss variables modification during the iterations.

The R software environment provides platform for simple and effective distribution of statistical models to a huge user community \citep{xiang_2013}. Thus, not surprisingly, several optimization packages of high quality can currently be purchased via \dfn{Comprehensive R Archive Network} \citep{theussl_2016} where even the SA method is recently listed 5 times. We, however, believe, a package which copes with very flexible loss functions and rules for the stochastic component could be an advantageous extension for R. We present the package \CRANpkg{optimization} where we implemented a modified version of SA. It is, as far as we know, the first function that combines SA with the extensions of \citet{corana_1987} and \citet{pronzato_1984}. Main difference of our approach to existing random-search methods is its flexibility. It allows several user specifications which help to parameterize the model very problem-specific. Next to the high number of parameters that may influence accuracy and speed of the solution, remarkable novelties of our model are the ability of flexibly defining loss function as well as covariate changing rules. The user can thus directly influence the stochastic part of the algorithm. Visual post-hoc inspection of the model convergence facilitate assessment of the solution quality. We show in practical examples where our model can be useful and how it can be parameterized.

\section{Method}
Simulated Annealing and its derivations are well document in the scientific literature \citep[e. g. in][]{hansen_2012,kirkpatrick_1983, xiang_2013}. We thus mainly concentrate in our methods description on modified and novel implementations. The classic SA is composed of an inner for and an outer while loop \citep{kirkpatrick_1983}. Since the basic idea of Simulated Annealing is derived from the physical process of metal annealing, the nomenclature of SA comes particularly from metallurgy. The number of iterations in both loops are user predefined.

\SetAlCapSkip{2ex}
\begin{algorithm}[H]
	initialize $t$, $vf$ with user specifications\\
	calculate $f(x_0)$ with initial parameter vector $x_0$\\
	\While{$t$ $>$ $t_{min}$}{
		\For{i in c(1: $n_{inner}$)}{
			$x_j \gets x_{(i-1)}$\\
			call the variation function to generate $x_{i*}$ in dependence of $x_{j}$, $rf$ and $t$\\
			check if all entries in $x_{i*}$ are within the boundaries\\
			\eIf{all $x_i$ valid}{calculate $f(x_{i*})$}{
				\While{any($x_{i*}$ invalid)}{
					call the variation function again\\
					count invalid combinations}
			}
			\eIf{$f(x_{i*}) < f(x_j)$}{
				$x_{i} \gets x_{i*}; f(x_{i}) \gets f(x_{i*})$
			}{calculate Metropolis Probability in dependence of $t$\\ \eIf{random 
				number $<$ Metropolis probability}{store $x_j$ and $f(x_j)$\\$x_{i} \gets x_{i*}; f(x_{i}) \gets f(x_{i*})$}{$x_{i} \gets x_j; f(x_{i}) \gets f(x_j)$}}
		\If{threshold accepting criterion fulfilled}{break inner loop}
	}
	
	{
		reduce $t$ for the next iteration\\
		$vf$ adaptation for the next iteration\\
	}
}
\textbf{return} optimized parameter vector, function value and some additional informations \\
\caption{Pseudocode of the modified Simulated Annealing method in the \textbf{optimization} package exemplary for a minimization.}
\label{algorithm:pseudocode}
\end{algorithm}

The inner loop of Algorithm \ref{algorithm:pseudocode} is a Markov-Chain in which the responses of different covariate combinations are calculated and compared. The loop is repeated $n_{inner}$ times. After saving the covariate combination of the last inner iteration as $x_j$, the variation function is called to create a new temporary combination $x_{i*}$. In the classical SA approach, the covariates are changed by a uniform distributed random number around $x_j$ \citep{kirkpatrick_1983} which is also the default in our function. The variation function can be changed by the user. It is allowed to depend on a vector with random factors $rf$, $x_j$ and the temperature $t$. By default, the entries in $rf$ determine the lower and upper limit of the uniformly distributed random number relative to the current expression of the covariate. A random factor of 0.1 and a covariate expression of 3 for $x_j$ e.g. leads to a random number between 2.7 and 3.3 for $x_{i*}$ if the covariate vector has one entry. The dynamic adaption of $rf$ after \citet{corana_1987} and \citet{pronzato_1984} is one of the major novelties of our function. If all entries in $x_{i*}$ after their variation are within the allowed boundaries, the response is calculated. Otherwise the invalid entries of $x_{i*}$ are drawn again until all entries are valid. According to \citet{corana_1987}, the number of invalid trials can be used for dynamical adjustment of the $rf$. The numbers of invalid trials are thus, distinctively for each covariate, counted and stored. If the return of current variables combination $f(x_{i*})$ is better than $f(x_j)$, $x_{i*}$ and $f(x_{i*})$ are stored. Main idea of the SA is to cope with local optima. For this, even if the return of $x_{i*}$ is worse than the return of $x_{j}$ there is a chance of keeping  $x_{i*}$. The former optimal covariate combination is stored before it is overwritten. The likelihood of keeping worse responses decreases with decreasing temperature $t$ thus with increasing number of outer loop iterations. The detailed calculation of the Monte-Carlo approach by \citet{metropolis_1953} can i.a. be found in \citet{kirkpatrick_1983}. Storing the development of covariates and response can be help improving the performance of SA \citep{lin_1995, hansen_2012}. We implemented a modification of the threshold accepting strategy \citep{dueck_1990} which enables reducing the total number of calculations. This is archived by simply calculating and storing the improvement as absolute difference of $f(x_{i})$ and $f(x_j)$. If the response oscillates for user defined number of repetitions within a user defined threshold, the inner loop breaks.

Main functions of the outer loop are calling the inner loop as well as specifying $t$ and $vf$ for the next iteration of the outer loop. As $t$ obligatory decreases in our derivation of SA, the number of iterations is implicitly user predefined by initial temperature $t_0$ and minimum temperature $t_{min}$. $t$ is necessary for the stochastic part within the inner loop \citep{kirkpatrick_1983}. As each covariate can have its own random factor, the vector with random factors $rf$ is of the same dimension as $x_i$. Dividing the counted number of invalid trials of a covariate by the total number of trials of the respective covariate gives the ratio of invalid trials distinctively for each covariate. Summing up the valid and invalid trials of all inner loop repetitions gives the mean ratio of invalid trials per outer loop repetition. According to \citep{corana_1987}, this ratio can be used to find a trade-off between accuracy on the one and size of the search-domain on the other side. They argument that if there were only valid covariate combinations, the search domain could be too small for multimodal function. They suggest ratios between 0.4 and 0.6. If any observed ratio is < 0.4 or > 0.6, the respective random factors are modified following the suggested nonlinear equation by \citet{corana_1987} such that they are dynamically adjusted for the next iteration. \citet{pronzato_1984}, who developed the Adaptive Random Search method, propose a time decreasing search domain. We combined the two methods by linearly shrinking the favorable range of ratios from 0.4-0.6 to 0.04-0.06. If the default variation function is chosen, the search domain of the covariates reduces with increasing number of outer loop iterations.

\textbf{May an additional graphical explanation be useful?}

\section{The package optimization}

\subsection{The function optim\_sa}
As the function is mainly written in C++, it requires \CRANpkg{Rcpp}. \code{optim\_sa} shall be able to solve very specific optimization problems, several parameters can be defined by the user. Quality of solution and speed of convergence will thus substantially depend on accurate parametrization. In the following, we will explain each parameter briefly giving hints for useful specification:
\begin{itemize}
	\item \code{fun}: Loss function to be optimized. The function must depend on a vector of covariates and return one numeric value. There are no assumptions on covariates and return. They are not necessarily continuous. Missing (\code{NA}) or undefined (\code{NaN}) returns are allowed as well. Any restriction on the parameter space, e. g. specific invalid covariate values within the boundaries, can be integrated in the loss function directly by simply returning NA. Restrictions on the state space can be defined analogously. We will be more specific on this in the practical examples.
	\item \code{start}: Obligatory numeric vector with initial covariate combination. It must be ensured that at least the initial covariate combination leads to a defined numeric response. The loss function at the start variables combination must therefore return a defined numeric value. This might be relevant when the starting values are determined stochastically.
	\item \code{maximization}: Logical value with default \code{FALSE} which indicates whether the loss function is to be maximized or minimized.
	\item \code{trace}: Logical value with default \code{FALSE}. If \code{TRUE}, the last inner loop iteration of each outer loop iteration is stored as row in the trace matrix. This might help evaluating the solutions quality. However, storing interim results increases calculation time up to 10 \%. Disabling \code{trace} can thus improve efficiency when the convergence of an optimization problem is known to be stable.
	\item \code{lower}: Numeric vector with lower boundaries of the covariates. The boundaries are obligatory since the dynamic \code{rf} adjustment \citep{corana_1987, pronzato_1984} depends on the number of invalid covariate combinations.
	\item \code{upper}: Numeric vector with upper boundaries of the covariates.
	\item \code{control}: A list with optional further parameters.
\end{itemize}
All parameters in the list with \code{control} arguments have a default value. They are pre-parameterized for loss functions of medium complexity. \code{control} arguments are:
\begin{itemize}
	\item \code{vf}: Function that determines the variation of covariates during the iterations. It is allowed to depend on \code{rf}, \code{temperature} and a vector of covariates of the current iteration. The variation function is a crucial element of \code{optim\_sa} which enables flexible programming. It is (next to the loss function itself) the second possibility to define restrictions. The parameter space of the optimization program can be defined \code{vf}. Per default, the covariates are changed by a continuous, uniform distributed random number. It must be considered that defining specific \code{rf} can increase the calculation time. The default \code{rf} is a compiled C++ function whereas user specified \code{rf} must be defined as R functions. User specified are e. g. useful for optimization problems with non-continuous parameter space.
	\item \code{rf}: Numeric vector with random factors. The random factors determine the range of the random number in the variation function vf relative to the dimension of the function variables. The rf can be stated separately for each variable. Default is a vector of ones. If \code{dyn\_rf} is enabled, the entries in \code{rf} change dynamically over time.
	\item \code{dyn\_rf}: Logical. Default is \code{TRUE} \code{rf} change dynamically over time to ensure increasing precision with increasing number of iterations. Default is \code{TRUE}. \code{dyn\_rf} ensures a relatively wide search domain at the beginning of the optimization process that shrinks over time \citep{corana_1987, pronzato_1984}. Disabling \code{dyn\_rf} can be useful when \code{rf} with high performance are known. The development of \code{rf} is documented in the \code{trace} matrix. Evaluation of former optimizations with dynamic \code{rf} can thus help finding reasonable fixed \code{rf}. Self-specified \code{vf} may not depend on \code{rf}. In this cases activating \code{dyn\_rf} makes no sense.
	\item \code{t0}: Initial temperature. Default is 1000. The temperature directly influences the likelihood of accepting worse responses thus the stochastic part of the optimization. \code{t0} should be adopted to the loss function complexity. Higher temperatures lead to higher ability of coping with local optima on the one but also to more time-consuming function calls on the other hand.
	\item \code{t\_min}: Numeric value that determines the temperature where outer loop stops. Default is 0.1. As there is approximately no chance of leaving local optima in iterations with low temperature \code{t\_min} mainly affects accuracy of the solution. Higher \code{t\_min} yields to lower accuracy and less function calls.
	\item \code{nlimit}: Integer value which determines the maximum number of inner loops iterations. Default is 100. If the break criterion \code{stopac} is not fulfilled, \code{nlimit} is the exact number of inner loops repetitions.
	\item \code{r}: Numeric value that determines the reduction of the temperature at the end of the outer loop. Slower temperature reduction leads to increasing number of function calls. It should be parameterized with respect to \code{nlimit}. High \code{nlimit} in combination with low \code{r} lead to many iterations with the same acceptance likelihood of worse responses. Low \code{nlimit} in combination with \code{r} near 1, by contrast, lead to continuously decreasing acceptance likelihood of worse responses.
	\item \code{k}: Numeric value. Constant for the Metropolis function \citep{kirkpatrick_1983}. Default is 1. \code{k} determines the global, non-dynamic likelihood of accepting worse responses. The higher \code{k} the higher the likelihood of accepting worse responses.
	\item \code{stopac}: Number of repetitions when the threshold accepting criterion is fulfilled. Can break the inner but not the outer loop.
	\item \code{ac\_acc}: Respective accuracy for the threshold accepting criterion in relation to the response. Very useful for optimization problems without high requirements on accuracy. Lower accuracy can speed-up the solution substantially.
\end{itemize}

\section{Practical examples}
We briefly explain where the \code{optim\_sa} function might be advantageous at 4 differing in their complexity.

\subsection{Himmelblau Function with continuous parameter space}
We chose Himmelblau's function \citep{himmelblau_1972} as initial example because it is a very simple multimodal equation which is widely known in Operations Research which has 4 equal minimum values ($min(f(x_1,x_2))=0)$). In order to display the advantages of \CRANpkg{optimization} and explain its basic behavior, we compared it with 2 other SA methods from the packages \CRANpkg{stats} and \CRANpkg{GenSA}. As the function is relatively simple we also included the NM direct search optimization method \citep{nelder_1965} which is default of \code{optim} from the \CRANpkg{stats} package.

\begin{equation}
\label{eq:eq1}
f(x_1,x_2)=(x_1^2+x_2-11)^2+(x_1+x_2^2-7)^2
\end{equation}

We performed 10,000 optimizations with different functions in order investigate quality and speed. We parameterized the \code{optim\_sa} function for relatively simple optimization problems. We tried to find parameters for all other investigated functions such the problem was solved properly. We performed optimizations having the following parameters:

\begin{example}
# stats::optim (NM)
optim(fn = hi, par = c(10, 10), method = "Nelder-Mead")
	
# optimization::optim_sa
optim_sa(fun = hi, start = (c(10, 10)), trace = TRUE, 
	lower = c(-40, -40), upper=c(40, 40),
		control = list(t0 = 500, nlimit = 50,r = 0.85,
		rf = 3, ac_acc = 0.1, dyn_rf = TRUE
		)
	)

# stats::optim (SA)
optim(fn = hi, par = c(10, 10), method = "SANN",
	control = list(tmax = 500, reltol = 0.1, temp = 50, trace = TRUE
		)
	)

# GenSA::GenSA
GenSA(fn = hi, par = c(10, 10), lower = c(-40, -40), upper = c(40, 40), 
	control = list(temperature = 50, nb.stop.improvement = 30, maxit = 500)
	)
\end{example}
%%Dont forget: No line break
Since we have a multimodal optimization problem, we must evaluate response as well as covariate combinations to rate the quality of the algorithms. Although starting parameter combination are fixed, the methods should be able to find all possible 4 solution. We defined the problem to be solved with sufficient accuracy when the response was $\leq$ 0.01 after minimization. We also looked at the frequency distribution of the covariate combination. After investigation of quality, we also compared the efficiencies by measuring calculation times using \CRANpkg{microbenchmark} with the same options except for the trace function.

% latex table generated in R 3.2.3 by xtable 1.8-2 package - Modified after pasting
% Tue Mar  7 14:26:30 2017
\begin{table}[]
	\centering
	\caption{Relative frequencies of covariate combinations in \% after optimization for the 4 examined methods. Number of repetitions: 10,000.}
	\label{tab:tab1}
	\begin{tabular}{cccccc}
		\cline{3-6}
		& \multicolumn{1}{c}{} & \multicolumn{4}{c}{Result (rounded)}                    \\ \cline{3-6} 
		&                      & \{-2.8, 3.1\} & \{3.0, 2.0\} & \{3.6, -1.8\} & \{-3.8, -3.3\} \\ \cline{2-6} 
		\multirow{4}{*}{Method} & optim\_sa          & 22.19     & 33.49    & 28.05     & 16.27      \\
		& optim (SA)            & 25.91     & 30.89    & 24.08     & 19.12      \\
		& GenSA              & 0.00      & 0.00     & 0.00      & 100.00     \\
		& optim (NM)          & 0.00      & 0.00     & 0.00      & 100.00     \\ \cline{2-6} 
	\end{tabular}
\end{table}

It could be seen that parameterization of NM was quite easy. It only needed a vector with starting values. The other functions needed much more settings. With view to accuracy each method performed well. All functions returned in mean of 10,000 calls responses $\leq$ 0.01 using the displayed parameters. All functions were thus generally able to find a proper solution. With view to frequency distribution the functions performed indifferent (Table \ref{tab:tab1}). \code{optim\_sa} and \code{optim (SA)} returned each possible solutions, where the covariate combination \{-3.8, -3.3\} was consistently less frequent. \code{GenSa} and \code{optim (NM)}, however, solely returned \{-3.8, -3.3\}. Further investigation revealed the solutions of \code{GenSa} and \code{optim (NM)} to be sensitive of the starting values. If \code{GenSa} and \code{optim (NM)} were parameterized with randomly drawn starting values, all 4 results would have been possible. Advantage of \code{optim\_sa} and \code{optim (SA)} against \code{GenSa} and \code{optim (NM)} is, in this example, thus its independence from starting values. If an optimization problem has multiple equivalent solutions, \code{optim (SA)} is able to archive each possible solution. Practically, in case users are in doubt whether a problem has multiple solutions, the function can be repeated without re-parameterization. If well-specified, \code{optim\_sa} will return all possible solutions within the parameter space.

As all functions were practically able to minimize equation \ref{eq:eq1}, comparison of calculation times appears to be another quite important point

\begin{figure}[htbp]
	\centering
	\resizebox{.75\linewidth}{!}{\input{test.tex}}
	\caption{test r-tikz. - truncated y-axis}
	\label{fig:fig1}
\end{figure}





\section{A complexer function?}
GenSA should be advantageous
\subsection{SVAR}
Alex
\subsection{Forest harvesting schedule optimization}
\section{Summary and discussion}
It does not guarantee, of course, to find the global minimum, but if the function has many good near- optimal solutions, it should find one. In particular, this method is able to discriminate between “gross behavior” of the function and finer “wrinkles.” First, it reaches an area in the function domain where a global minimum should be present, following the gross behavior irrespectively of small local minima found on the way. It then develops finer details, finding a good, near-optimal local minimum, if not the global minimum itself.\\

This section may contain a figure such as Figure~\ref{figure:rlogo}.
This file is only a basic article template. For full details of \emph{The R Journal} style and information on how to prepare your article for submission, see the \href{http://journal.r-project.org/share/author-guide.pdf}{Instructions for Authors}.

\begin{figure}[htbp]
	\centering
	\includegraphics{Fig/Rlogo}
	\caption{The logo of R.}
	\label{figure:rlogo}
\end{figure}

\bibliography{husmann}

\address{Author One\\
  Affiliation\\
  Address\\
  Country\\}
\email{author1@work}

\address{Author Two\\
  Affiliation\\
  Address\\
  Country\\}
\email{author2@work}

\address{Author Three\\
  Affiliation\\
  Address\\
  Country\\}
\email{author3@work}
